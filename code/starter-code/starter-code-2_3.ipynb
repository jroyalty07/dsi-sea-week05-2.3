{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Pipeline Lab\n",
    "\n",
    "\n",
    "## 1. Data loading\n",
    "In this lab we will create pipelines for data processing on the [Titanic dataset](http://www.kaggle.com/c/titanic-gettingStarted/data).\n",
    "\n",
    "The dataset is a list of passengers. The second column of the dataset is a “label” for each person indicating whether that person survived (1) or did not survive (0). Here is the Kaggle page with more information on the dataset:\n",
    "\n",
    "You can grab the titanic data as follows:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Survived  Pclass  \\\n",
       "0      0            1         0       3   \n",
       "1      1            2         1       1   \n",
       "2      2            3         1       3   \n",
       "3      3            4         1       1   \n",
       "4      4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "connect_param = 'postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com:5432/titanic'\n",
    "engine_titanic = create_engine(connect_param)\n",
    "\n",
    "query = pd.read_sql(\"SELECT * FROM pg_catalog.pg_tables WHERE schemaname='public'\", con=engine_titanic)\n",
    "query = pd.read_sql(\"SELECT * FROM train\", con=engine_titanic)\n",
    "query.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data using the info method:\n",
    "\n",
    "- Are there numerical features?\n",
    "- Are there categorical features?\n",
    "- Which columns have missing data?\n",
    "- Which of these are important to be filled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "index          891 non-null int64\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "query.info()\n",
    "# Mix of numerical and categorical features\n",
    "# Age, Cabin, and Embarked have nulls\n",
    "# Age and embarked aren't missing many so should be filled, but cabin is missing most of the data so\n",
    "# it is much harder to fill, and other features will probably overshadow it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Age\n",
    "\n",
    "Several passengers are missing data points for age. Impute the missing values so that there are no “NaN” values for age as inputs to your model. Explore the distribution of age and decide how you are going to impute the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query.drop(\"Cabin\", axis = 1, inplace = True)\n",
    "query.drop(\"PassengerId\", axis = 1, inplace = True)\n",
    "query.drop(\"Ticket\", axis = 1, inplace = True)\n",
    "query.drop(\"Name\", axis = 1, inplace = True)\n",
    "query = query[pd.notnull(query['Embarked'])]\n",
    "# Can I add in age values based on known ages w/ other features?\n",
    "# or is the random/std/mean of the distribution fill better?\n",
    "\n",
    "titanic = query\n",
    "df = query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Age Transformer\n",
    "\n",
    "Create a custom transformer that imputes the age values. Depending on how you have decided to impute missing values, this could involve:\n",
    "\n",
    "- Selecting one or more columns\n",
    "- Filling the NAs using Imputer or a custom strategy\n",
    "- Scaling the Age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC r^2: \n",
      "0.285221367066\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, preprocessing\n",
    "# prep for dummification\n",
    "titanic_test = titanic\n",
    "titanic_test['Pclass'] = titanic_test['Pclass'].astype(str)\n",
    "titanic_test['SibSp'] = titanic_test['SibSp'].astype(str)\n",
    "titanic_test['Parch'] = titanic_test['Parch'].astype(str)\n",
    "\n",
    "# Exclude ID for modeling, unique ID = row index\n",
    "col_minus_index = titanic.columns.values[1:]\n",
    "\n",
    "y = titanic_test[pd.notnull(titanic_test['Age'])]['Age']\n",
    "\n",
    "titanic_test = pd.get_dummies(titanic_test[col_minus_index])\n",
    "\n",
    "#The subset where age is not null\n",
    "titanic_nons = titanic_test[pd.notnull(titanic_test['Age'])].drop(\"Age\",axis = 1)\n",
    "\n",
    "#The subset where age is null\n",
    "titanic_nulls = titanic_test[pd.isnull(titanic_test['Age'])].drop(\"Age\", axis = 1)\n",
    "\n",
    "X = titanic_nons\n",
    "\n",
    "# predict ages\n",
    "X_titanic_nulls = titanic_nulls\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "lm.fit(X_train,y_train)\n",
    "print \"ACC r^2: \"\n",
    "print lm.score(X_test,y_test)\n",
    "\n",
    "#Do it\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X,y)\n",
    "\n",
    "ages = lm.predict(X_titanic_nulls)\n",
    "\n",
    "titanic_nulls['Age'] = ages\n",
    "stuff = pd.DataFrame(titanic_nulls['Age'])\n",
    "stuff.head()\n",
    "\n",
    "#titanic and age left join\n",
    "# then merge new age col with original age column\n",
    "#df['age'] = [df['old'] if df['old']notnull else df['new']]\n",
    "titanic['index'] = titanic.index.values\n",
    "stuff['index'] = stuff.index.values\n",
    "\n",
    "mergy = titanic.merge(stuff, how = \"left\", on = \"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived Pclass     Sex SibSp Parch     Fare Embarked   Age\n",
       "0         0      3    male     1     0   7.2500        S  22.0\n",
       "1         1      1  female     1     0  71.2833        C  38.0\n",
       "2         1      3  female     0     0   7.9250        S  26.0\n",
       "3         1      1  female     1     0  53.1000        S  35.0\n",
       "4         0      3    male     0     0   8.0500        S  35.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergy['Age'] = mergy['Age_y'].fillna(mergy['Age_x'])\n",
    "titanic = mergy.drop([\"Age_x\",\"Age_y\",\"index\"],axis = 1)\n",
    "# #mergy.ix[mergy['Age_y'].isnull(),'Age_y'] = mergy['Age_x']\n",
    "titanic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.58961986],\n",
       "       [ 0.64484799],\n",
       "       [-0.28100289],\n",
       "       [ 0.41338527],\n",
       "       [ 0.41338527]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return pd.DataFrame(X[self.columns])\n",
    "        else:\n",
    "            raise TypeError(\"This transformer only works with Pandas Dataframes\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "\n",
    "\n",
    "# my custom method didn't work very well.\n",
    "age_pipe = make_pipeline(ColumnSelector('Age'),\n",
    "                         Imputer(),\n",
    "                         StandardScaler())\n",
    "\n",
    "#Shows that the columnselector works, and that they were imputed + scaled\n",
    "#also starting with a fresh DF\n",
    "age_pipe.fit_transform(df)[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Categorical Variables\n",
    "\n",
    "`Embarked` and `Pclass` are categorical variables. Use pandas get_dummies function to create dummy columns corresponding to the values.\n",
    "\n",
    "`Embarked` has 2 missing values. Fill them with the most common port of embarkment.\n",
    "\n",
    "Feel free to create a GetDummiesTransformer that wraps around the get_dummies function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Embarked'].value_counts()\n",
    "df['Embarked'] = df['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gets the dummies for all of the different classifications, allows chaining\n",
    "class GetDummiesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return pd.get_dummies(X[self.columns], columns = self.columns)\n",
    "        else:\n",
    "            raise TypeError(\"This transformer only works with Pandas Dataframes\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "\n",
    "one_hot_pipe = GetDummiesTransformer(['Pclass', 'Embarked'])\n",
    "#one_hot_pipe.fit_transform(df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Boolean Columns\n",
    "\n",
    "The `Sex` column only contains 2 values: `male` and `female`. Build a custom transformers that is initialized with one of the values and returns a boolean column with values of `True` when that value is found and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gets the dummies for all of the different classifications, allows chaining\n",
    "\n",
    "class BinaryTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, flag):\n",
    "        #set the flag conditional\n",
    "        self.flag = flag\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        return X == self.flag\n",
    "\n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set True if male\n",
    "gender_pipe = make_pipeline(ColumnSelector('Sex'),\n",
    "                            BinaryTransformer('male'))\n",
    "\n",
    "#gender_pipe.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fare\n",
    "\n",
    "The `Fare` attribute can be scaled using one of the scalers from the preprocessing module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fare_pipe = make_pipeline(ColumnSelector('Fare'),\n",
    "                         StandardScaler())\n",
    "#fare_pipe.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Union\n",
    "\n",
    "Use the `make_union` function from the `sklearn.pipeline` modeule to combine all the pipes you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes all of the different column transforms I have done and puts them together.\n",
    "union = make_union(age_pipe,\n",
    "                   one_hot_pipe,\n",
    "                   gender_pipe,\n",
    "                   fare_pipe)\n",
    "\n",
    "#union.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The union you have created is a complete pre-processing pipeline that takes the original titanic dataset and extracts a bunch of features out of it. The last step of this process is to persist the `union` object to disk, so that it can be used again later. The following lines achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "import gzip\n",
    "\n",
    "with gzip.open('../../assets/datasets/union.dill.gz', 'w') as fout:\n",
    "    dill.dump(union, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Can you think of a way to engineer an additional boolean feature that keeps track whethere the person is travelling alone or with family?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Yes, just have a binary for if ParCh and SibSp are <1, false if >=1\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
